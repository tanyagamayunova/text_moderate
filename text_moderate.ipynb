{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igAVZZ9YxEu5"
      },
      "source": [
        "# Модерация текстов\n",
        "<b>Задача:</b> Создать модель, которая будет определять эмоциональную окраску текста и пропускать его или же отправлять на модерацию. Построить модель со значением метрики качества F1 не меньше 0.75.<br>\n",
        "<b>Дано:</b> Набор текстов с разметкой их эмоциональной окраски. На основе этих данных модель должна научиться классифицировать текст как позитивный или негативный."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqfORdDhxErR"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JKszX1w_a8n",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94150ac-8f1f-436d-a7b0-56d87fac4262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga4lVbLPakUb",
        "outputId": "570fc53f-a5be-4f38-d76f-0aa25de2f5d4",
        "trusted": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from catboost import CatBoostClassifier, Pool, cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pl0xPLZ146t",
        "outputId": "3663e8a5-c44c-47bc-e315-daead31ae057",
        "trusted": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доля негативных твитов в датасете: 0.1\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
        "\n",
        "corpus = data['text']\n",
        "\n",
        "print('Доля негативных твитов в датасете:', round(data['toxic'].sum() / len(data['toxic']), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCTN8G9-OrSZ",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "stopwords = list(stopwords.words('english'))\n",
        "\n",
        "def clear_text(text):\n",
        "    text_sub = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
        "    return ' '.join(text_sub.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qysHShdRPbj-",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423d8a66-a123-4376-8a9e-1df0d707a168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159292/159292 [16:51<00:00, 157.49it/s]\n"
          ]
        }
      ],
      "source": [
        "corpus_lemm = []\n",
        "\n",
        "for doc in tqdm(nlp.pipe(corpus.apply(clear_text), batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(corpus)):\n",
        "    word_list = [tok.lemma_ for tok in doc]\n",
        "    corpus_lemm.append(' '.join(word_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2lt7P8MblD8"
      },
      "source": [
        "### Вывод\n",
        "Провели первичную подготовку данных. Тексты твитов выгружены в корпус, проведена лемматизация и убраны стоп-слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-X0NZv3Ygxb"
      },
      "source": [
        "## Векторизация текстов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWLStgYVZAbC",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    corpus_lemm, data['toxic'], test_size=0.3, random_state=12345, stratify=data['toxic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRwTgGDtblD-"
      },
      "source": [
        "### Вывод\n",
        "Проведено разбитие выборки на тренировочную и тестовую с учетом стратификации по целевому признаку, далее выборки были преобразованы в векторы TF-IDF для дальнейшей передачи в модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCWK-zu6dNYR"
      },
      "source": [
        "## Обучение моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElKMKkZOdWND"
      },
      "source": [
        "### Дамми модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKarXQWwbcEK",
        "outputId": "e5257236-3235-4018-8bbd-b301c3208b41",
        "trusted": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера для дамми модели = 0.0\n",
            "Accuracy для дамми модели = 0.8983845316815937\n"
          ]
        }
      ],
      "source": [
        "predictions = pd.Series(0, index=np.arange(len(y_test)))\n",
        "print('F1-мера для дамми модели =', f1_score(y_test, predictions, zero_division=1))\n",
        "print('Accuracy для дамми модели =', accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "127RkZ_nblD_"
      },
      "source": [
        "Дамми модель, заполненная нулями (т.к. 90% датасета - это комментарии положительного эмоционального окраса), выдает ожидаемую accuracy ~89%, но при этом F1-мера недостаточна джля дальнейшего сравнения с этой моделью."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwFCohqQ-GKg"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
        "    ('logreg', LogisticRegression(random_state=42, max_iter=500)),\n",
        "])\n",
        "parameters = {'logreg__C' : [1e-2, 1e-1, 1, 10, 30],\n",
        "              'logreg__penalty': ['l1', 'l2', 'elasticnet']}\n",
        "\n",
        "lr = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=1)\n",
        "scores_lr = lr.fit(X_train, y_train)\n",
        "print('Лучшая F1-мера для LogisticRegression', round(scores_lr.best_score_, 3))\n",
        "print(scores_lr.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzph_YP2uI2h",
        "outputId": "def37642-809f-4d67-de67-be414ac54d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 45.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.02268418        nan        nan 0.44672223        nan\n",
            "        nan 0.71612912        nan        nan 0.76831059        nan\n",
            "        nan 0.76651681        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая F1-мера для LogisticRegression 0.768\n",
            "{'logreg__C': 10, 'logreg__penalty': 'l2'}\n",
            "CPU times: user 6min 9s, sys: 2min 37s, total: 8min 47s\n",
            "Wall time: 6min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3w5I3jAblEB"
      },
      "source": [
        "### LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
        "    ('lsvc', LinearSVC(max_iter = 500)),\n",
        "])\n",
        "parameters = {'lsvc__C': np.linspace(1, 31, num = 7, endpoint = True)}\n",
        "\n",
        "model_lsvc = GridSearchCV(pipeline, parameters, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
        "scores_lsvc  = model_lsvc.fit(X_train, y_train)\n",
        "print('Лучшая F1-мера для LinearSVC', round(scores_lsvc.best_score_, 3))\n",
        "print(scores_lsvc.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czNg_dzG4R6w",
        "outputId": "233ccacd-1df5-4a38-b8b6-607bb5b5cd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "Лучшая F1-мера для LinearSVC 0.778\n",
            "{'lsvc__C': 1.0}\n",
            "CPU times: user 12.4 s, sys: 3.29 s, total: 15.7 s\n",
            "Wall time: 5min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY40xHQ9blEB"
      },
      "source": [
        "### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
        "    ('dtc', DecisionTreeClassifier(random_state=12345)),\n",
        "])\n",
        "parameters =  {\n",
        "    'dtc__min_samples_leaf': [1, 2],\n",
        "    'dtc__max_depth': [6, 30, 100]\n",
        "}\n",
        "\n",
        "model_dtc = GridSearchCV(pipeline, parameters, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
        "scores_dtc  = model_dtc.fit(X_train, y_train)\n",
        "print('Лучшая F1-мера для DecisionTreeClassifier', round(scores_dtc.best_score_, 3))\n",
        "print(scores_dtc.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj200K4P47AI",
        "outputId": "ba20414e-b182-426c-b5a5-7f527fe2cc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Лучшая F1-мера для DecisionTreeClassifier 0.727\n",
            "{'dtc__max_depth': 100, 'dtc__min_samples_leaf': 1}\n",
            "CPU times: user 1min 20s, sys: 2.94 s, total: 1min 23s\n",
            "Wall time: 12min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvqRklzqblED"
      },
      "source": [
        "### Вывод\n",
        "Были проверены разные модели классификации с подбором гиперпараметров. Лучшие результаты показала модель решающего дерева, но вероятно эта цифра может говорить о переобчуении. Однако, она обучалась дольше всех других моделей, около 1 минуты после подбора гиперпараметров, что заняло 20 минут. Если для задачи важно время обучения модели, то стоит рекомендовать модель опорных векторов, обучение модели происходит меньбше, чем за секунду, показатели F1-меры удовлетворяют условию задачи. Эту модель можно передать на тестирование.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llDfXKIEblED"
      },
      "source": [
        "## Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSVdIV9NblEE",
        "outputId": "9cced0ec-7347-4041-ed94-e7d28a5d51b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера на тестовой выборке для LinearSVC модели 0.78\n"
          ]
        }
      ],
      "source": [
        "predictions = model_lsvc.predict(X_test)\n",
        "print('F1-мера на тестовой выборке для LinearSVC модели', round(f1_score(predictions, y_test), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKlSemUJblEE"
      },
      "source": [
        "### Вывод\n",
        "Модель опорных векторов прошла тестирование и показала удовлетворительный результат по заказанной метрике. Моджель можно рекомендовать заказчику."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akh8D-o9blEE"
      },
      "source": [
        "## Общий вывод\n",
        "Была проведена работа по построению модели для анализа эмоциональной окраски поступающего текста и определения его как допустимого или же требующего модерации. Входными данными был датасет с размеченными текстами, по этим данным была создана модель, отвечающая поставленной задаче. Заказчику рекомендована модель LinearSVC (C=1), которая очень быстра в работе и выдает хороший результат по заданной метрике (F1-мера) на тесте."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}